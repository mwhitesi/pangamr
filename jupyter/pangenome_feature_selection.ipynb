{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "__Name__: pangenome_feature_selection<br/>\n",
    "__Description__: Try out feature selection methods<br/>\n",
    "__Author__: Matthew Whiteside matthew dot whiteside at canada dot ca<br/>\n",
    "__Date__: Oct 23, 2017<br/>\n",
    "__TODO__:<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_classifier, xgboost_classification, random_forest, gradient_boosting, extra_trees\n",
    "from hyperopt import tpe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10.0,8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../pangenome')\n",
    "import config\n",
    "import utils\n",
    "import classify\n",
    "pg, genome_list, locus_list = utils.read_panseq(config.PANSEQ['pangenome_file'])\n",
    "amr, amr_list = utils.read_amr(config.PHENOTYPE['amr_file'], genome_list)\n",
    "annot = utils.read_annot(config.ANNOTATION['blast_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train & test for ampicillin\n",
    "d = np.argwhere(amr_list == 'ampicillin').item(0)\n",
    "validrows = ~np.isnan(amr[:,d])\n",
    "validrows\n",
    "X = pg[validrows,:]\n",
    "y = amr[validrows,d]\n",
    "\n",
    "test_size = int( 0.2 * len( y ) )\n",
    "np.random.seed( 2123 )\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "X_train = X[ indices[:-test_size] ]\n",
    "y_train = y[ indices[:-test_size] ]\n",
    "X_test = X[ indices[-test_size:] ]\n",
    "y_test = y[ indices[-test_size:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867647058824\n",
      "{'learner': RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=4,\n",
      "            max_features=0.766719831648635, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=20, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.75      0.67        12\n",
      "        1.0       0.94      0.89      0.92        56\n",
      "\n",
      "avg / total       0.88      0.87      0.87        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "def loss_fn(y_target, y_prediction):\n",
    "    return 1.0 - f1_score(y_target, y_prediction)\n",
    "# HP search for Random Forest\n",
    "rfc = HyperoptEstimator( classifier=random_forest('rfc'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "rfc.fit( X_train.toarray(), y_train )\n",
    "print( rfc.score( X_test.toarray(), y_test ) )\n",
    "print( rfc.best_model() )\n",
    "predictions = rfc.predict( X_test.toarray() )\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features=0.8493329707313447,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1535, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=False,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcb = rfc._best_learner\n",
    "rfcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867647058824\n",
      "{'learner': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.005308968883120171, loss='deviance',\n",
      "              max_depth=None, max_features=0.2973197785199644,\n",
      "              max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=562,\n",
      "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
      "              warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.67      0.64        12\n",
      "        1.0       0.93      0.91      0.92        56\n",
      "\n",
      "avg / total       0.87      0.87      0.87        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HP search for Gradient Boost\n",
    "gbc = HyperoptEstimator( classifier=gradient_boosting('gbc'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "gbc.fit( X_train.toarray(), y_train )\n",
    "print( gbc.score( X_test.toarray(), y_test ) )\n",
    "print( gbc.best_model() )\n",
    "predictions = gbc.predict( X_test.toarray() )\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.005308968883120171, loss='deviance',\n",
       "              max_depth=None, max_features=0.2973197785199644,\n",
       "              max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=562,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbcb = gbc._best_learner\n",
    "gbcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955882352941\n",
      "{'learner': RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=None,\n",
      "            max_features=0.4452771242357403, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=19, n_jobs=1, oob_score=False, random_state=1,\n",
      "            verbose=False, warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.88      0.82         8\n",
      "        1.0       0.98      0.97      0.97        60\n",
      "\n",
      "avg / total       0.96      0.96      0.96        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = SelectKBest(chi2, k=2000)\n",
    "X_new_train = fs.fit_transform(X_train,y_train)\n",
    "X_new_test = fs.transform(X_test)\n",
    "rfc2 = HyperoptEstimator( classifier=random_forest('rfc'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "rfc2.fit( X_new_train.toarray(), y_train )\n",
    "print( rfc2.score( X_new_test.toarray(), y_test ) )\n",
    "print( rfc2.best_model() )\n",
    "predictions2 = rfc2.predict( X_new_test.toarray() )\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [0 0 0 ..., 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/home/matt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941176470588\n",
      "{'learner': RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=None, max_features='log2',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2784, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=False,\n",
      "            warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67         8\n",
      "        1.0       0.94      1.00      0.97        60\n",
      "\n",
      "avg / total       0.94      0.94      0.93        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = SelectKBest(f_classif, k=2000)\n",
    "X_new_train = fs.fit_transform(X_train,y_train)\n",
    "X_new_test = fs.transform(X_test)\n",
    "rfc2 = HyperoptEstimator( classifier=random_forest('rfc'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "rfc2.fit( X_new_train.toarray(), y_train )\n",
    "print( rfc2.score( X_new_test.toarray(), y_test ) )\n",
    "print( rfc2.best_model() )\n",
    "predictions2 = rfc2.predict( X_new_test.toarray() )\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852941176471\n",
      "{'learner': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.35008535557916565,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=11, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=170, n_jobs=1,\n",
      "            oob_score=False, random_state=3, verbose=False,\n",
      "            warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.75      0.64        12\n",
      "        1.0       0.94      0.88      0.91        56\n",
      "\n",
      "avg / total       0.88      0.85      0.86        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = SelectKBest(mutual_info_classif, k=2000)\n",
    "X_new_train = fs.fit_transform(X_train,y_train)\n",
    "X_new_test = fs.transform(X_test)\n",
    "rfc2 = HyperoptEstimator( classifier=random_forest('rfc'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "rfc2.fit( X_new_train.toarray(), y_train )\n",
    "print( rfc2.score( X_new_test.toarray(), y_test ) )\n",
    "print( rfc2.best_model() )\n",
    "predictions2 = rfc2.predict( X_new_test.toarray() )\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try stacked implementation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rf, X_train_lr, y_train_rf, y_train_lr = train_test_split(X_train,\n",
    "                                                            y_train,\n",
    "                                                            test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised transformation based on gradient boosting\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=4, max_features=0.8493329707313447,\n",
    "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=3, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1535, n_jobs=4,\n",
    "            oob_score=False, random_state=0, verbose=False,\n",
    "            warm_start=False)\n",
    "rf_enc = OneHotEncoder()\n",
    "rf_lm = LogisticRegression()\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "rf_enc.fit(rf.apply(X_train_rf))\n",
    "rf_lm.fit(rf_enc.transform(rf.apply(X_train_lr)), y_train_lr, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_rf_lm = rf_lm.predict(rf_enc.transform(rf.apply(X_test)))\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.67      0.64        12\n",
      "        1.0       0.93      0.91      0.92        56\n",
      "\n",
      "avg / total       0.87      0.87      0.87        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.33      0.47        12\n",
      "        1.0       0.87      0.98      0.92        56\n",
      "\n",
      "avg / total       0.86      0.87      0.84        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  4],\n",
       "       [ 5, 51]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rf_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.005308968883120171, loss='deviance',\n",
    "              max_depth=None, max_features=0.2973197785199644,\n",
    "              max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=562,\n",
    "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "grd_enc = OneHotEncoder()\n",
    "grd_lm = LogisticRegression()\n",
    "grd.fit(X_train, y_train)\n",
    "grd_enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "grd_lm.fit(grd_enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.75      0.72        12\n",
      "        1.0       0.95      0.93      0.94        56\n",
      "\n",
      "avg / total       0.90      0.90      0.90        68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.67      0.64        12\n",
      "        1.0       0.93      0.91      0.92        56\n",
      "\n",
      "avg / total       0.87      0.87      0.87        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_grd_lm = grd_lm.predict(grd_enc.transform(grd.apply(X_test)[:, :, 0]))\n",
    "y_pred_grd = grd.predict(X_test.toarray())\n",
    "print(classification_report(y_test, y_pred_grd_lm))\n",
    "print(classification_report(y_test, y_pred_grd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838235294118\n",
      "{'learner': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=0.4105662978479582,\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=2982, n_jobs=1,\n",
      "           oob_score=False, random_state=2, verbose=False,\n",
      "           warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.53      0.75      0.62        12\n",
      "        1.0       0.94      0.86      0.90        56\n",
      "\n",
      "avg / total       0.87      0.84      0.85        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etc = HyperoptEstimator( classifier=extra_trees('et'), preprocessing=[], algo=tpe.suggest, loss_fn=loss_fn, trial_timeout=2000)\n",
    "etc.fit( X_train.toarray(), y_train )\n",
    "print( etc.score( X_test.toarray(), y_test ) )\n",
    "print( etc.best_model() )\n",
    "predictions = etc.predict( X_test.toarray() )\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
